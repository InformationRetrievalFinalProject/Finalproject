{"cells":[{"cell_type":"markdown","id":"a00e032c","metadata":{"id":"hWgiQS0zkWJ5"},"source":["***Important*** DO NOT CLEAR THE OUTPUT OF THIS NOTEBOOK AFTER EXECUTION!!!"]},{"cell_type":"code","execution_count":7,"id":"5ac36d3a","metadata":{"id":"c0ccf76b","nbgrader":{"grade":false,"grade_id":"cell-Worker_Count","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"cf88b954-f39a-412a-d87e-660833e735b6"},"outputs":[{"name":"stdout","output_type":"stream","text":["NAME          PLATFORM  PRIMARY_WORKER_COUNT  SECONDARY_WORKER_COUNT  STATUS   ZONE           SCHEDULED_DELETE\r\n","cluster-978e  GCE       4                                             RUNNING  us-central1-a\r\n"]}],"source":["# if the following command generates an error, you probably didn't enable \n","# the cluster security option \"Allow API access to all Google Cloud services\"\n","# under Manage Security â†’ Project Access when setting up the cluster\n","!gcloud dataproc clusters list --region us-central1"]},{"cell_type":"markdown","id":"51cf86c5","metadata":{"id":"01ec9fd3"},"source":["# Imports & Setup"]},{"cell_type":"code","execution_count":8,"id":"bf199e6a","metadata":{"id":"32b3ec57","nbgrader":{"grade":false,"grade_id":"cell-Setup","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"fc0e315d-21e9-411d-d69c-5b97e4e5d629"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\n","\u001B[0m"]}],"source":["!pip install -q google-cloud-storage==1.43.0\n","!pip install -q graphframes"]},{"cell_type":"code","execution_count":9,"id":"d8f56ecd","metadata":{"id":"5609143b","nbgrader":{"grade":false,"grade_id":"cell-Imports","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"a24aa24b-aa75-4823-83ca-1d7deef0f0de"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import math\n","import pyspark\n","import sys\n","from collections import Counter, OrderedDict, defaultdict\n","import itertools\n","from itertools import islice, count, groupby\n","import pandas as pd\n","import os\n","import re\n","from operator import itemgetter\n","import nltk\n","from nltk.stem.porter import *\n","from nltk.corpus import stopwords\n","from time import time\n","from pathlib import Path\n","import pickle\n","import pandas as pd\n","from google.cloud import storage\n","\n","import hashlib\n","def _hash(s):\n","    return hashlib.blake2b(bytes(s, encoding='utf8'), digest_size=5).hexdigest()\n","\n","nltk.download('stopwords')"]},{"cell_type":"code","execution_count":10,"id":"38a897f2","metadata":{"id":"b10cc999","nbgrader":{"grade":false,"grade_id":"cell-jar","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"8f93a7ec-71e0-49c1-fc81-9af385849a90"},"outputs":[{"name":"stdout","output_type":"stream","text":["-rw-r--r-- 1 root root 247882 Mar  4 18:34 /usr/lib/spark/jars/graphframes-0.8.2-spark3.1-s_2.12.jar\r\n"]}],"source":["# if nothing prints here you forgot to include the initialization script when starting the cluster\n","!ls -l /usr/lib/spark/jars/graph*"]},{"cell_type":"code","execution_count":11,"id":"47900073","metadata":{"id":"d3f86f11","nbgrader":{"grade":false,"grade_id":"cell-pyspark-import","locked":true,"schema_version":3,"solution":false,"task":false}},"outputs":[],"source":["from pyspark.sql import *\n","from pyspark.sql.functions import *\n","from pyspark import SparkContext, SparkConf, SparkFiles\n","from pyspark.sql import SQLContext\n","from graphframes import *"]},{"cell_type":"code","execution_count":12,"id":"72bed56b","metadata":{"id":"5be6dc2a","nbgrader":{"grade":false,"grade_id":"cell-spark-version","locked":true,"schema_version":3,"solution":false,"task":false},"outputId":"07b4e22b-a252-42fb-fe46-d9050e4e7ca8","scrolled":true},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://cluster-978e-m.c.irproject-414719.internal:40099\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7ff8d64f7490>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":13,"id":"980e62a5","metadata":{"id":"7adc1bf5","nbgrader":{"grade":false,"grade_id":"cell-bucket_name","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# Put your bucket name below and make sure you can access it without an error\n","bucket_name = 'irproject-414719bucket' \n","full_path = f\"gs://{bucket_name}/\"\n","paths=[]\n","\n","client = storage.Client()\n","blobs = client.list_blobs(bucket_name)\n","for b in blobs:\n","    if b.name != 'graphframes.sh' and not b.name.startswith(\"postings_gcp\") and not b.name.startswith(\"page_views\") and not b.name.startswith(\"postings_gcp_Title\") and not b.name.startswith(\"bucketText\") and not b.name.startswith(\"bucketTitle\") and not b.name.startswith(\"page_ranks\"):\n","        paths.append(full_path+b.name)"]},{"cell_type":"markdown","id":"cac891c2","metadata":{"id":"13ZX4ervQkku"},"source":["***GCP setup is complete!*** If you got here without any errors you've earned 10 out of the 35 points of this part."]},{"cell_type":"markdown","id":"582c3f5e","metadata":{"id":"c0b0f215"},"source":["# Building an inverted index"]},{"cell_type":"markdown","id":"481f2044","metadata":{"id":"02f81c72"},"source":["Here, we read the entire corpus to an rdd, directly from Google Storage Bucket and use your code from Colab to construct an inverted index."]},{"cell_type":"code","execution_count":14,"id":"e4c523e7","metadata":{"id":"b1af29c9","scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["parquetFile = spark.read.parquet(*paths)\n","doc_text_pairs = parquetFile.select(\"anchor_text\", \"id\").rdd"]},{"cell_type":"markdown","id":"0d7e2971","metadata":{"id":"f6375562"},"source":["We will count the number of pages to make sure we are looking at the entire corpus. The number of pages should be more than 6M"]},{"cell_type":"code","execution_count":15,"id":"82881fbf","metadata":{"id":"d89a7a9a"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["6348910"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Count number of wiki pages\n","parquetFile.count()"]},{"cell_type":"markdown","id":"701811af","metadata":{"id":"gaaIoFViXyTg"},"source":["Let's import the inverted index module. Note that you need to use the staff-provided version called `inverted_index_gcp.py`, which contains helper functions to writing and reading the posting files similar to the Colab version, but with writing done to a Google Cloud Storage bucket."]},{"cell_type":"code","execution_count":16,"id":"121fe102","metadata":{"id":"04371c88","outputId":"327fe81b-80f4-4b3a-8894-e74720d92e35"},"outputs":[{"name":"stdout","output_type":"stream","text":["inverted_index_gcp.py\r\n"]}],"source":["# if nothing prints here you forgot to upload the file inverted_index_gcp.py to the home dir\n","%cd -q /home/dataproc\n","!ls inverted_index_gcp.py"]},{"cell_type":"code","execution_count":17,"id":"57c101a8","metadata":{"id":"2d3285d8","scrolled":true},"outputs":[],"source":["# adding our python module to the cluster\n","sc.addFile(\"/home/dataproc/inverted_index_gcp.py\")\n","sys.path.insert(0,SparkFiles.getRootDirectory())"]},{"cell_type":"code","execution_count":18,"id":"c259c402","metadata":{"id":"2477a5b9"},"outputs":[],"source":["from inverted_index_gcp import InvertedIndex"]},{"cell_type":"markdown","id":"5540c727","metadata":{"id":"72bcf46a"},"source":["**YOUR TASK (10 POINTS)**: Use your implementation of `word_count`, `reduce_word_counts`, `calculate_df`, and `partition_postings_and_write` functions from Colab to build an inverted index for all of English Wikipedia in under 2 hours.\n","\n","A few notes: \n","1. The number of corpus stopwords below is a bit bigger than the colab version since we are working on the whole corpus and not just on one file.\n","2. You need to slightly modify your implementation of  `partition_postings_and_write` because the signature of `InvertedIndex.write_a_posting_list` has changed and now includes an additional argument called `bucket_name` for the target bucket. See the module for more details.\n","3. You are not allowed to change any of the code not coming from Colab. "]},{"cell_type":"code","execution_count":19,"id":"f3ad8fea","metadata":{"id":"a4b6ee29","nbgrader":{"grade":false,"grade_id":"cell-token2bucket","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["english_stopwords = frozenset(stopwords.words('english'))\n","corpus_stopwords = ['category', 'references', 'also', 'links', 'extenal', 'see', 'thumb', 'became', 'may']\n","RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){2,24}\"\"\", re.UNICODE)\n","all_stopwords = english_stopwords.union(corpus_stopwords)\n","stemmer = PorterStemmer()\n","\n","NUM_BUCKETS = 124\n","def token2bucket_id(token):\n","    return int(_hash(token),16) % NUM_BUCKETS\n","\n","#####################################################################################################\n","stemDict = {}\n","\n","def word_count(ListOfAnchors, id):\n","    \n","    sizeOfDoc = 0\n","    word_counts = Counter()\n","    \n","    for _ , text in ListOfAnchors:\n","        tokens = [token.group() for token in RE_WORD.finditer(text.lower())]\n","\n","        for token in tokens:\n","            if (token not in all_stopwords):\n","                if(token in stemDict):\n","                    word_counts[stemDict[token]] += 1\n","                else:\n","                    stemDict[token] = stemmer.stem(token)\n","                    word_counts[stemDict[token]] += 1\n","\n","                sizeOfDoc += 1\n","\n","    if len(stemDict) >= 20000:\n","        stemDict.clear()\n","\n","    return [(token, (id, count, sizeOfDoc)) for token, count in word_counts.items()]\n","\n","#####################################################################################################\n","\n","def reduce_word_counts(unsorted_pl):\n","    return sorted(unsorted_pl, key=lambda x: x[0])\n","\n","#####################################################################################################\n","\n","def calculate_df(postings):\n","    return postings.map(lambda x: (x[0], len(x[1])))\n","\n","#####################################################################################################\n","\n","def partition_postings_and_write(postings):\n","\n","    bucketed_postings = postings.map(lambda x: (token2bucket_id(x[0]), [(x[0], x[1])]))         \n","    grouped_postings = bucketed_postings.reduceByKey(lambda x, y: x + y)                        \n","    posting_locations = grouped_postings.map(lambda x: InvertedIndex.write_a_posting_list(x, 'bucketAnchorText', bucket_name))   \n","\n","    return posting_locations\n","\n","#####################################################################################################\n","\n"]},{"cell_type":"code","execution_count":20,"id":"55c8764e","metadata":{"id":"0b5d7296","nbgrader":{"grade":false,"grade_id":"cell-index_construction","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[{"name":"stderr","output_type":"stream","text":["24/03/04 18:52:12 WARN YarnAllocator: Container from a bad node: container_1709577226282_0001_01_000011 on host: cluster-978e-w-2.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 18:52:12.140]Container killed on request. Exit code is 143\n","[2024-03-04 18:52:12.141]Container exited with a non-zero exit code 143. \n","[2024-03-04 18:52:12.142]Killed by external signal\n",".\n","24/03/04 18:52:12 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 11 for reason Container from a bad node: container_1709577226282_0001_01_000011 on host: cluster-978e-w-2.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 18:52:12.140]Container killed on request. Exit code is 143\n","[2024-03-04 18:52:12.141]Container exited with a non-zero exit code 143. \n","[2024-03-04 18:52:12.142]Killed by external signal\n",".\n","24/03/04 18:52:12 ERROR YarnScheduler: Lost executor 11 on cluster-978e-w-2.c.irproject-414719.internal: Container from a bad node: container_1709577226282_0001_01_000011 on host: cluster-978e-w-2.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 18:52:12.140]Container killed on request. Exit code is 143\n","[2024-03-04 18:52:12.141]Container exited with a non-zero exit code 143. \n","[2024-03-04 18:52:12.142]Killed by external signal\n",".\n","24/03/04 18:52:12 WARN TaskSetManager: Lost task 48.0 in stage 5.0 (TID 234) (cluster-978e-w-2.c.irproject-414719.internal executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709577226282_0001_01_000011 on host: cluster-978e-w-2.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 18:52:12.140]Container killed on request. Exit code is 143\n","[2024-03-04 18:52:12.141]Container exited with a non-zero exit code 143. \n","[2024-03-04 18:52:12.142]Killed by external signal\n",".\n","24/03/04 18:52:52 WARN YarnAllocator: Container from a bad node: container_1709577226282_0001_01_000016 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 18:52:52.117]Container killed on request. Exit code is 143\n","[2024-03-04 18:52:52.117]Container exited with a non-zero exit code 143. \n","[2024-03-04 18:52:52.118]Killed by external signal\n",".\n","24/03/04 18:52:52 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 16 for reason Container from a bad node: container_1709577226282_0001_01_000016 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 18:52:52.117]Container killed on request. Exit code is 143\n","[2024-03-04 18:52:52.117]Container exited with a non-zero exit code 143. \n","[2024-03-04 18:52:52.118]Killed by external signal\n",".\n","24/03/04 18:52:52 ERROR YarnScheduler: Lost executor 16 on cluster-978e-w-1.c.irproject-414719.internal: Container from a bad node: container_1709577226282_0001_01_000016 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 18:52:52.117]Container killed on request. Exit code is 143\n","[2024-03-04 18:52:52.117]Container exited with a non-zero exit code 143. \n","[2024-03-04 18:52:52.118]Killed by external signal\n",".\n","24/03/04 18:52:52 WARN TaskSetManager: Lost task 52.0 in stage 5.0 (TID 238) (cluster-978e-w-1.c.irproject-414719.internal executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709577226282_0001_01_000016 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 18:52:52.117]Container killed on request. Exit code is 143\n","[2024-03-04 18:52:52.117]Container exited with a non-zero exit code 143. \n","[2024-03-04 18:52:52.118]Killed by external signal\n",".\n","24/03/04 19:01:35 WARN TaskSetManager: Lost task 80.0 in stage 9.0 (TID 662) (cluster-978e-w-0.c.irproject-414719.internal executor 14): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n","  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 686, in main\n","    process()\n","  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 678, in process\n","    serializer.dump_stream(out_iter, outfile)\n","  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 273, in dump_stream\n","    vs = list(itertools.islice(iterator, batch))\n","  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n","    return f(*args, **kwargs)\n","  File \"/tmp/ipykernel_10089/3696623272.py\", line 53, in <lambda>\n","  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1709577226282_0001/container_1709577226282_0001_01_000014/inverted_index_gcp.py\", line 194, in write_a_posting_list\n","    with _open(path, 'wb', bucket) as f:\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/fileio.py\", line 428, in close\n","    self._upload_chunks_from_buffer(1)\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/fileio.py\", line 407, in _upload_chunks_from_buffer\n","    upload.transmit_next_chunk(transport)\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/upload.py\", line 515, in transmit_next_chunk\n","    return _request_helpers.wait_and_retry(\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/_request_helpers.py\", line 178, in wait_and_retry\n","    raise error\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/_request_helpers.py\", line 155, in wait_and_retry\n","    response = func()\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/upload.py\", line 511, in retriable_request\n","    self._process_resumable_response(result, len(payload))\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/_upload.py\", line 690, in _process_resumable_response\n","    status_code = _helpers.require_status_code(\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/_helpers.py\", line 108, in require_status_code\n","    raise common.InvalidResponse(\n","google.resumable_media.common.InvalidResponse: ('Request failed with status code', 503, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PERMANENT_REDIRECT: 308>)\n","\n","\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:552)\n","\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:758)\n","\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:740)\n","\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:505)\n","\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n","\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n","\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n","\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n","\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n","\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n","\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n","\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n","\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n","\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n","\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n","\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n","\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n","\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n","\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n","\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n","\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n","\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1021)\n","\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2333)\n","\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1505)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","\n","24/03/04 19:01:36 WARN TaskSetManager: Lost task 88.0 in stage 9.0 (TID 666) (cluster-978e-w-3.c.irproject-414719.internal executor 21): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n","  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1709577226282_0001/container_1709577226282_0001_01_000021/inverted_index_gcp.py\", line 189, in write_a_posting_list\n","    locs = writer.write(b)\n","  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1709577226282_0001/container_1709577226282_0001_01_000021/inverted_index_gcp.py\", line 46, in write\n","    self._f.close()\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/fileio.py\", line 428, in close\n","    self._upload_chunks_from_buffer(1)\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/fileio.py\", line 407, in _upload_chunks_from_buffer\n","    upload.transmit_next_chunk(transport)\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/upload.py\", line 515, in transmit_next_chunk\n","    return _request_helpers.wait_and_retry(\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/_request_helpers.py\", line 178, in wait_and_retry\n","    raise error\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/_request_helpers.py\", line 155, in wait_and_retry\n","    response = func()\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/upload.py\", line 511, in retriable_request\n","    self._process_resumable_response(result, len(payload))\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/_upload.py\", line 690, in _process_resumable_response\n","    status_code = _helpers.require_status_code(\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/_helpers.py\", line 108, in require_status_code\n","    raise common.InvalidResponse(\n","google.resumable_media.common.InvalidResponse: ('Request failed with status code', 503, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PERMANENT_REDIRECT: 308>)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 686, in main\n","    process()\n","  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 678, in process\n","    serializer.dump_stream(out_iter, outfile)\n","  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 273, in dump_stream\n","    vs = list(itertools.islice(iterator, batch))\n","  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n","    return f(*args, **kwargs)\n","  File \"/tmp/ipykernel_10089/3696623272.py\", line 53, in <lambda>\n","  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1709577226282_0001/container_1709577226282_0001_01_000021/inverted_index_gcp.py\", line 183, in write_a_posting_list\n","    with closing(MultiFileWriter(base_dir, bucket_id, bucket_name)) as writer:\n","  File \"/opt/conda/miniconda3/lib/python3.10/contextlib.py\", line 340, in __exit__\n","    self.thing.close()\n","  File \"/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1709577226282_0001/container_1709577226282_0001_01_000021/inverted_index_gcp.py\", line 56, in close\n","    self._f.close()\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/fileio.py\", line 428, in close\n","    self._upload_chunks_from_buffer(1)\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/cloud/storage/fileio.py\", line 407, in _upload_chunks_from_buffer\n","    upload.transmit_next_chunk(transport)\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/requests/upload.py\", line 503, in transmit_next_chunk\n","    method, url, payload, headers = self._prepare_request()\n","  File \"/opt/conda/miniconda3/lib/python3.10/site-packages/google/resumable_media/_upload.py\", line 627, in _prepare_request\n","    raise ValueError(msg)\n","ValueError: Bytes stream is in unexpected state. The local stream has had 1999998 bytes read from it while 0 bytes have already been updated (they should match).\n","\n","\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:552)\n","\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:758)\n","\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:740)\n","\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:505)\n","\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n","\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n","\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n","\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n","\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n","\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n","\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n","\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n","\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n","\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n","\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n","\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n","\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n","\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n","\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n","\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n","\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n","\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1021)\n","\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2333)\n","\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n","\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n","\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n","\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1505)\n","\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n","\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n","\tat java.base/java.lang.Thread.run(Thread.java:829)\n","\n","                                                                                \r"]}],"source":["word_counts = doc_text_pairs.flatMap(lambda x: word_count(x[0], x[1]))\n","word_counts_withNotSize = word_counts.map(lambda x: (x[0], (x[1][0], x[1][1])))\n","\n","postings = word_counts_withNotSize.groupByKey().mapValues(reduce_word_counts)\n","postings_filtered = postings.filter(lambda x: len(x[1])>20)\n","\n","w2df_dict = calculate_df(postings_filtered).collectAsMap()\n","\n","_ = partition_postings_and_write(postings_filtered).collect()\n","\n","super_posting_locs = defaultdict(list)\n","for blob in client.list_blobs(bucket_name, prefix='bucketAnchorText'):\n","    if not blob.name.endswith(\"pickle\"):\n","        continue\n","    with blob.open(\"rb\") as f:\n","        posting_locs = pickle.load(f)\n","        for k, v in posting_locs.items():\n","            super_posting_locs[k].extend(v)\n","\n","\n"]},{"cell_type":"code","execution_count":21,"id":"7a538ed7","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/03/04 19:07:58 WARN YarnAllocator: Container from a bad node: container_1709577226282_0001_01_000022 on host: cluster-978e-w-3.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:07:58.146]Container killed on request. Exit code is 143\n","[2024-03-04 19:07:58.146]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:07:58.146]Killed by external signal\n",".\n","24/03/04 19:07:58 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 22 for reason Container from a bad node: container_1709577226282_0001_01_000022 on host: cluster-978e-w-3.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:07:58.146]Container killed on request. Exit code is 143\n","[2024-03-04 19:07:58.146]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:07:58.146]Killed by external signal\n",".\n","24/03/04 19:07:58 ERROR YarnScheduler: Lost executor 22 on cluster-978e-w-3.c.irproject-414719.internal: Container from a bad node: container_1709577226282_0001_01_000022 on host: cluster-978e-w-3.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:07:58.146]Container killed on request. Exit code is 143\n","[2024-03-04 19:07:58.146]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:07:58.146]Killed by external signal\n",".\n","24/03/04 19:07:58 WARN TaskSetManager: Lost task 31.0 in stage 10.0 (TID 717) (cluster-978e-w-3.c.irproject-414719.internal executor 22): ExecutorLostFailure (executor 22 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709577226282_0001_01_000022 on host: cluster-978e-w-3.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:07:58.146]Container killed on request. Exit code is 143\n","[2024-03-04 19:07:58.146]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:07:58.146]Killed by external signal\n",".\n","24/03/04 19:08:23 WARN YarnAllocator: Container from a bad node: container_1709577226282_0001_01_000015 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:08:23.224]Container killed on request. Exit code is 143\n","[2024-03-04 19:08:23.225]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:08:23.225]Killed by external signal\n",".\n","24/03/04 19:08:23 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 15 for reason Container from a bad node: container_1709577226282_0001_01_000015 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:08:23.224]Container killed on request. Exit code is 143\n","[2024-03-04 19:08:23.225]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:08:23.225]Killed by external signal\n",".\n","24/03/04 19:08:23 ERROR YarnScheduler: Lost executor 15 on cluster-978e-w-1.c.irproject-414719.internal: Container from a bad node: container_1709577226282_0001_01_000015 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:08:23.224]Container killed on request. Exit code is 143\n","[2024-03-04 19:08:23.225]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:08:23.225]Killed by external signal\n",".\n","24/03/04 19:08:23 WARN TaskSetManager: Lost task 37.0 in stage 10.0 (TID 723) (cluster-978e-w-1.c.irproject-414719.internal executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709577226282_0001_01_000015 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:08:23.224]Container killed on request. Exit code is 143\n","[2024-03-04 19:08:23.225]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:08:23.225]Killed by external signal\n",".\n","24/03/04 19:10:08 WARN YarnAllocator: Container from a bad node: container_1709577226282_0001_01_000014 on host: cluster-978e-w-0.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:10:08.630]Container killed on request. Exit code is 143\n","[2024-03-04 19:10:08.631]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:10:08.631]Killed by external signal\n",".\n","24/03/04 19:10:08 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 14 for reason Container from a bad node: container_1709577226282_0001_01_000014 on host: cluster-978e-w-0.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:10:08.630]Container killed on request. Exit code is 143\n","[2024-03-04 19:10:08.631]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:10:08.631]Killed by external signal\n",".\n","24/03/04 19:10:08 ERROR YarnScheduler: Lost executor 14 on cluster-978e-w-0.c.irproject-414719.internal: Container from a bad node: container_1709577226282_0001_01_000014 on host: cluster-978e-w-0.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:10:08.630]Container killed on request. Exit code is 143\n","[2024-03-04 19:10:08.631]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:10:08.631]Killed by external signal\n",".\n","24/03/04 19:10:08 WARN TaskSetManager: Lost task 46.0 in stage 10.0 (TID 734) (cluster-978e-w-0.c.irproject-414719.internal executor 14): ExecutorLostFailure (executor 14 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709577226282_0001_01_000014 on host: cluster-978e-w-0.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:10:08.630]Container killed on request. Exit code is 143\n","[2024-03-04 19:10:08.631]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:10:08.631]Killed by external signal\n",".\n","24/03/04 19:13:51 WARN YarnAllocator: Container from a bad node: container_1709577226282_0001_01_000019 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:13:51.034]Container killed on request. Exit code is 143\n","[2024-03-04 19:13:51.036]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:13:51.036]Killed by external signal\n",".\n","24/03/04 19:13:51 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 19 for reason Container from a bad node: container_1709577226282_0001_01_000019 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:13:51.034]Container killed on request. Exit code is 143\n","[2024-03-04 19:13:51.036]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:13:51.036]Killed by external signal\n",".\n","24/03/04 19:13:51 ERROR YarnScheduler: Lost executor 19 on cluster-978e-w-1.c.irproject-414719.internal: Container from a bad node: container_1709577226282_0001_01_000019 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:13:51.034]Container killed on request. Exit code is 143\n","[2024-03-04 19:13:51.036]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:13:51.036]Killed by external signal\n",".\n","24/03/04 19:13:51 WARN TaskSetManager: Lost task 71.0 in stage 10.0 (TID 760) (cluster-978e-w-1.c.irproject-414719.internal executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Container from a bad node: container_1709577226282_0001_01_000019 on host: cluster-978e-w-1.c.irproject-414719.internal. Exit status: 143. Diagnostics: [2024-03-04 19:13:51.034]Container killed on request. Exit code is 143\n","[2024-03-04 19:13:51.036]Container exited with a non-zero exit code 143. \n","[2024-03-04 19:13:51.036]Killed by external signal\n",".\n","                                                                                \r"]}],"source":["Doc_TF = word_counts.map(lambda x: (x[1][0], x[1][2])).distinct()\n","Doc_TF = Doc_TF.collectAsMap()"]},{"cell_type":"code","execution_count":22,"id":"7e06134f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CommandException: No URLs matched: indexAnchorText.pkl\r\n"]}],"source":["inverted = InvertedIndex()\n","inverted.posting_locs = super_posting_locs\n","inverted.df = w2df_dict\n","inverted.nf = Doc_TF\n","inverted.write_index('bucketAnchorText', 'indexAnchorText', bucket_name)\n","\n","index_src = \"indexAnchorText.pkl\"\n","index_dst = f'gs://{bucket_name}/bucketAnchorText/{index_src}'\n","!gsutil cp $index_src $index_dst"]},{"cell_type":"code","execution_count":23,"id":"8f880d59","metadata":{"id":"msogGbJ3c8JF","nbgrader":{"grade":false,"grade_id":"cell-index_dst_size","locked":true,"schema_version":3,"solution":false,"task":false}},"outputs":[{"name":"stdout","output_type":"stream","text":[" 55.31 MiB  2024-03-04T19:17:30Z  gs://irproject-414719bucket/bucketAnchorText/indexAnchorText.pkl\r\n","TOTAL: 1 objects, 57993678 bytes (55.31 MiB)\r\n"]}],"source":["!gsutil ls -lh $index_dst"]}],"metadata":{"celltoolbar":"Create Assignment","colab":{"collapsed_sections":[],"name":"assignment3_gcp.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}